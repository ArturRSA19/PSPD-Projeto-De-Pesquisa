# Relat√≥rio Final - Projeto de Monitoramento e Observabilidade em Kubernetes

---

## Dados de Identifica√ß√£o

**Curso:** Engenharia de Computa√ß√£o  
**Disciplina:** PSPD - Programa√ß√£o para Sistemas Paralelos e Distribu√≠dos  
**Professor:** Fernando W. Cruz  
**Data:** 6 de Dezembro de 2025  

**Integrantes do Grupo:**
- [Nome do Aluno 1] - Matr√≠cula: [XXXXXX]
- [Nome do Aluno 2] - Matr√≠cula: [XXXXXX]
- [Nome do Aluno 3] - Matr√≠cula: [XXXXXX]
- [Nome do Aluno 4] - Matr√≠cula: [XXXXXX]

---

## 1. Introdu√ß√£o

Este projeto teve como objetivo explorar estrat√©gias de monitoramento e observabilidade de aplica√ß√µes baseadas em microservi√ßos em ambiente Kubernetes, com foco em m√©tricas de desempenho. O trabalho envolveu a cria√ß√£o de uma aplica√ß√£o distribu√≠da usando gRPC, a configura√ß√£o de um cluster Kubernetes multi-n√≥, a implementa√ß√£o de ferramentas de monitoramento (Prometheus e Grafana), e a realiza√ß√£o de testes de carga em diferentes cen√°rios de autoscaling.

### Estrutura do Relat√≥rio

Este documento est√° organizado nas seguintes se√ß√µes:
- **Se√ß√£o 2:** Metodologia utilizada pelo grupo
- **Se√ß√£o 3:** Experi√™ncia de montagem do Kubernetes em modo cluster
- **Se√ß√£o 4:** Monitoramento e observabilidade com Prometheus/Grafana
- **Se√ß√£o 5:** Descri√ß√£o da aplica√ß√£o e arquitetura
- **Se√ß√£o 6:** Cen√°rios de teste e resultados
- **Se√ß√£o 7:** Conclus√µes e considera√ß√µes finais
- **Se√ß√£o 8:** Refer√™ncias bibliogr√°ficas
- **Anexos:** Informa√ß√µes t√©cnicas adicionais

---

## 2. Metodologia Utilizada

### 2.1 Organiza√ß√£o do Grupo

[Descrever como o grupo se organizou para realizar o projeto]

### 2.2 Cronograma de Encontros e Atividades

| Data | Atividade Realizada | Respons√°veis |
|------|---------------------|--------------|
| [Data] | Defini√ß√£o da arquitetura da aplica√ß√£o | [Nomes] |
| [Data] | Implementa√ß√£o do Gateway (Node.js) | [Nomes] |
| [Data] | Implementa√ß√£o do Service-A (Python) | [Nomes] |
| [Data] | Implementa√ß√£o do Service-B (Go) | [Nomes] |
| [Data] | Setup do cluster Kubernetes | [Nomes] |
| [Data] | Configura√ß√£o do Prometheus e Grafana | [Nomes] |
| [Data] | Desenvolvimento dos scripts de teste | [Nomes] |
| [Data] | Execu√ß√£o dos cen√°rios de teste | [Nomes] |
| [Data] | An√°lise de resultados e documenta√ß√£o | [Nomes] |

### 2.3 Divis√£o de Tarefas

- **[Nome]:** [Descri√ß√£o das responsabilidades]
- **[Nome]:** [Descri√ß√£o das responsabilidades]
- **[Nome]:** [Descri√ß√£o das responsabilidades]
- **[Nome]:** [Descri√ß√£o das responsabilidades]

---

## 3. Experi√™ncia de Montagem do Kubernetes em Modo Cluster

### 3.1 Escolha da Plataforma

Para este projeto, optamos por utilizar o **Minikube** em modo multi-n√≥, executando localmente em ambiente macOS. Esta escolha permitiu:
- Simula√ß√£o realista de um cluster Kubernetes
- Facilidade de experimenta√ß√£o e debugging
- Controle total sobre a configura√ß√£o do ambiente
- Custo zero de infraestrutura

### 3.2 Configura√ß√£o do Cluster

#### 3.2.1 Especifica√ß√µes do Cluster

- **Plano de Controle:** 1 n√≥ mestre
- **Worker Nodes:** 2 n√≥s escravos
- **Driver:** Docker
- **CPUs por n√≥:** 2
- **Mem√≥ria por n√≥:** 2048MB
- **Kubernetes Version:** [Vers√£o utilizada]

#### 3.2.2 Processo de Instala√ß√£o

O cluster foi configurado atrav√©s do script `scripts/setup_cluster.sh`:

```bash
#!/bin/bash
# Configura√ß√£o do cluster Kubernetes multi-n√≥
minikube start --nodes 3 --cpus 2 --memory 2048 --driver=docker
kubectl label nodes minikube-m02 node-role.kubernetes.io/worker=worker
kubectl label nodes minikube-m03 node-role.kubernetes.io/worker=worker
```

**Passos realizados:**
1. Instala√ß√£o do Minikube e kubectl
2. Configura√ß√£o do driver Docker
3. Cria√ß√£o do cluster com 3 n√≥s
4. Rotula√ß√£o dos n√≥s worker
5. Verifica√ß√£o do estado do cluster
6. Habilita√ß√£o de addons necess√°rios (metrics-server, ingress)

**Comandos de verifica√ß√£o:**
```bash
kubectl get nodes
kubectl cluster-info
```

### 3.3 Desafios Encontrados

#### 3.3.1 Limita√ß√µes de Recursos
[Descrever desafios relacionados a recursos computacionais e como foram resolvidos]

#### 3.3.2 Networking
[Descrever desafios de networking e solu√ß√µes implementadas]

#### 3.3.3 Persist√™ncia de Dados
[Descrever como foi tratada a quest√£o de volumes e persist√™ncia]

### 3.4 Estrutura de Deployment

A aplica√ß√£o foi organizada em namespaces e deployments conforme documentado em `k8s/`:
- **Namespace:** `grpc-app`
- **Gateway:** 1-3 r√©plicas (conforme cen√°rio)
- **Service-A:** 1-3 r√©plicas (conforme cen√°rio)
- **Service-B:** 1-3 r√©plicas (conforme cen√°rio)

---

## 4. Monitoramento e Observabilidade

### 4.1 Prometheus

#### 4.1.1 Instala√ß√£o e Configura√ß√£o

O Prometheus foi instalado utilizando o Helm Chart oficial, atrav√©s do script `scripts/setup_prometheus.sh`:

```bash
#!/bin/bash
# Instala√ß√£o do Prometheus via Helm
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo update
helm install prometheus prometheus-community/kube-prometheus-stack \
  --namespace monitoring --create-namespace
```

#### 4.1.2 ServiceMonitors Configurados

Foram criados ServiceMonitors customizados para cada servi√ßo da aplica√ß√£o (`k8s/servicemonitors.yaml`):
- **Gateway ServiceMonitor:** Coleta m√©tricas HTTP do Node.js
- **Service-A ServiceMonitor:** Coleta m√©tricas da aplica√ß√£o Python
- **Service-B ServiceMonitor:** Coleta m√©tricas da aplica√ß√£o Go

#### 4.1.3 M√©tricas Coletadas

**M√©tricas de Sistema:**
- CPU usage (por pod e por n√≥)
- Mem√≥ria usage (por pod e por n√≥)
- Network I/O
- Disk I/O

**M√©tricas de Aplica√ß√£o:**
- Throughput (requisi√ß√µes por segundo)
- Lat√™ncia (p50, p95, p99)
- Taxa de erro
- N√∫mero de r√©plicas ativas

**M√©tricas de gRPC:**
- Dura√ß√£o de chamadas gRPC
- Status de resposta
- Volume de dados trafegados

### 4.2 Grafana

#### 4.2.1 Acesso ao Grafana

O Grafana foi instalado como parte do stack do Prometheus e pode ser acessado via port-forward:

```bash
kubectl port-forward -n monitoring svc/prometheus-grafana 3000:80
# Acesso: http://localhost:3000
# Credenciais padr√£o: admin/prom-operator
```

#### 4.2.2 Dashboards Utilizados

**Dashboards Pr√©-configurados:**
- **Node Exporter / Nodes:** M√©tricas detalhadas dos 3 n√≥s do cluster (CPU, mem√≥ria, disco, rede do host)
- **Kubernetes / Compute Resources / Namespace:** Visualiza√ß√£o de CPU Quota (requests e limits configurados)

**Queries Diretas no Prometheus:**

Para monitoramento detalhado da aplica√ß√£o e do comportamento do HPA, utilizamos queries diretas no Prometheus:

```promql
# N√∫mero de r√©plicas por deployment
kube_deployment_status_replicas{namespace="grpc-app"}

# CPU utilizado (target do HPA)
container_cpu_usage_seconds_total{namespace="grpc-app"}

# Pods em execu√ß√£o
kube_pod_status_phase{namespace="grpc-app"}

# Status do HPA
kube_horizontalpodautoscaler_status_current_replicas{namespace="grpc-app"}
```

**Ferramentas Complementares:**

Al√©m do Grafana, utilizamos extensivamente:
- `kubectl get hpa -n grpc-app` para monitorar autoscaling em tempo real
- `kubectl get pods -n grpc-app` para verificar estado das r√©plicas
- `kubectl top nodes` para verificar carga dos n√≥s
- Logs dos testes k6 para m√©tricas de performance da aplica√ß√£o

#### 4.2.3 Observa√ß√µes sobre Monitoramento

O stack Prometheus/Grafana foi configurado com sucesso, permitindo:
- ‚úÖ Monitoramento da sa√∫de dos n√≥s do cluster
- ‚úÖ Valida√ß√£o de configura√ß√µes de recursos (CPU/Memory requests e limits)
- ‚úÖ Queries customizadas para m√©tricas espec√≠ficas do HPA
- ‚úÖ Integra√ß√£o com ServiceMonitors dos servi√ßos da aplica√ß√£o

A an√°lise principal de desempenho foi realizada atrav√©s dos **resultados detalhados do k6**, que forneceram m√©tricas precisas de lat√™ncia, throughput e taxa de erro. O Prometheus serviu como ferramenta complementar para validar o comportamento do autoscaling e a sa√∫de geral do cluster durante os testes.

#### 4.2.4 Exemplos de Visualiza√ß√£o

**Figura 1: Dashboard Node Exporter - M√©tricas dos N√≥s do Cluster**

![Dashboard Node Exporter Grafana]

*[INSERIR PRINT AQUI: Screenshot do dashboard Node Exporter do Grafana mostrando m√©tricas de CPU, mem√≥ria e rede de um dos n√≥s do cluster Kubernetes]*

**Figura 2: Prometheus - Evolu√ß√£o das R√©plicas do HPA**

![Prometheus HPA Replicas]

*[INSERIR PRINT AQUI: Screenshot do Prometheus com a query `kube_horizontalpodautoscaler_status_current_replicas{namespace="pspd-lab"}` no modo Graph, mostrando a evolu√ß√£o do n√∫mero de r√©plicas dos deployments ao longo do tempo durante os testes]*

### 4.3 Horizontal Pod Autoscaler (HPA)

#### 4.3.1 Configura√ß√£o Normal

Arquivo: `k8s/hpa.yaml`

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: gateway-hpa
  namespace: grpc-app
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: gateway
  minReplicas: 1
  maxReplicas: 3
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
```

#### 4.3.2 Configura√ß√£o Agressiva

Arquivo: `k8s/hpa-agressivo.yaml`

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: gateway-hpa
  namespace: grpc-app
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: gateway
  minReplicas: 1
  maxReplicas: 5
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 50
  behavior:
    scaleUp:
      stabilizationWindowSeconds: 0
      policies:
      - type: Percent
        value: 100
        periodSeconds: 15
      - type: Pods
        value: 2
        periodSeconds: 15
    scaleDown:
      stabilizationWindowSeconds: 60
      policies:
      - type: Percent
        value: 50
        periodSeconds: 15
```

**Diferen√ßas principais:**
- Threshold de CPU reduzido (50% vs 70%)
- M√°ximo de r√©plicas aumentado (5 vs 3)
- Scale-up mais r√°pido (sem janela de estabiliza√ß√£o)
- Pol√≠ticas agressivas de escalamento

---

## 5. Aplica√ß√£o Baseada em Microservi√ßos

### 5.1 Arquitetura da Aplica√ß√£o

A aplica√ß√£o foi desenvolvida seguindo uma arquitetura de microservi√ßos com comunica√ß√£o gRPC:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Usu√°rio/      ‚îÇ
‚îÇ   Load Test     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ HTTP REST
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Gateway       ‚îÇ
‚îÇ   (Node.js)     ‚îÇ
‚îÇ   Port: 8080    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ       ‚îÇ
     ‚îÇ gRPC  ‚îÇ gRPC
     ‚ñº       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇService-A‚îÇ ‚îÇService-B‚îÇ
‚îÇ(Python) ‚îÇ ‚îÇ  (Go)   ‚îÇ
‚îÇPort:50051‚îÇ ‚îÇPort:50052‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 5.2 Descri√ß√£o dos Servi√ßos

#### 5.2.1 Gateway (Node.js)

**Responsabilidades:**
- Receber requisi√ß√µes HTTP REST dos clientes
- Converter requisi√ß√µes REST para chamadas gRPC
- Orquestrar chamadas para Service-A e Service-B
- Consolidar respostas e retornar ao cliente

**Endpoints:**
- `GET /healthz` - Health check
- `POST /users` - Criar usu√°rio (chama Service-A)
- `GET /users` - Listar usu√°rios (chama Service-A)
- `GET /stats/:id` - Obter estat√≠sticas (chama Service-B)

**Tecnologias:**
- Node.js 18
- Express.js para API REST
- @grpc/grpc-js para comunica√ß√£o gRPC
- Protocol Buffers para serializa√ß√£o

**Arquivo:** `gateway-node/src/index.js`

#### 5.2.2 Service-A (Python)

**Responsabilidades:**
- Gerenciar dados de usu√°rios
- Implementar opera√ß√µes CRUD via gRPC
- Fornecer lista de usu√°rios cadastrados

**M√©todos gRPC:**
- `CreateUser(UserRequest) returns (UserResponse)`
- `GetUsers(Empty) returns (UsersListResponse)`

**Tecnologias:**
- Python 3.11
- grpcio para servidor gRPC
- Protocol Buffers para serializa√ß√£o

**Arquivo:** `service-a-python/server.py`

#### 5.2.3 Service-B (Go)

**Responsabilidades:**
- Calcular estat√≠sticas sobre usu√°rios
- Processar dados sob demanda
- Retornar m√©tricas agregadas

**M√©todos gRPC:**
- `GetUserStats(StatsRequest) returns (StatsResponse)`

**Tecnologias:**
- Go 1.21
- google.golang.org/grpc
- Protocol Buffers para serializa√ß√£o

**Arquivo:** `service-b-go/server.go`

### 5.3 Protocol Buffers

O contrato de comunica√ß√£o entre os servi√ßos √© definido em `proto/users.proto`:

```protobuf
syntax = "proto3";

package users;
option go_package = "github.com/user/pspd";

service UserService {
  rpc CreateUser (UserRequest) returns (UserResponse);
  rpc GetUsers (Empty) returns (UsersListResponse);
}

service StatsService {
  rpc GetUserStats (StatsRequest) returns (StatsResponse);
}

message UserRequest {
  string name = 1;
  string email = 2;
}

message UserResponse {
  int32 id = 1;
  string name = 2;
  string email = 3;
}

message Empty {}

message UsersListResponse {
  repeated UserResponse users = 1;
}

message StatsRequest {
  int32 user_id = 1;
}

message StatsResponse {
  int32 user_id = 1;
  int32 total_requests = 2;
  string status = 3;
}
```

### 5.4 Containeriza√ß√£o

Cada servi√ßo foi containerizado usando Docker:

**Gateway Dockerfile:**
```dockerfile
FROM node:18-alpine
WORKDIR /app
COPY package*.json ./
RUN npm install
COPY . .
EXPOSE 8080
CMD ["node", "src/index.js"]
```

**Service-A Dockerfile:**
```dockerfile
FROM python:3.11-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY . .
EXPOSE 50051
CMD ["python", "server.py"]
```

**Service-B Dockerfile:**
```dockerfile
FROM golang:1.21-alpine AS builder
WORKDIR /app
COPY go.mod go.sum ./
RUN go mod download
COPY . .
RUN go build -o server .

FROM alpine:latest
WORKDIR /root/
COPY --from=builder /app/server .
EXPOSE 50052
CMD ["./server"]
```

### 5.5 Vers√£o B√°sica da Aplica√ß√£o

**Configura√ß√£o inicial para baseline:**
- Gateway: 1 r√©plica
- Service-A: 1 r√©plica
- Service-B: 1 r√©plica
- Sem autoscaling habilitado
- Limites de recursos definidos mas sem otimiza√ß√£o

**Caracter√≠sticas de desempenho observadas:**
- Lat√™ncia m√©dia: ~100ms
- Throughput m√°ximo: ~50 req/s
- Taxa de erro: < 1%

---

## 6. Cen√°rios de Teste e Resultados

### 6.1 Ferramenta de Teste de Carga

#### 6.1.1 Escolha da Ferramenta

Utilizamos o **k6** (https://k6.io) para realizar os testes de carga. A escolha foi baseada em:
- Suporte nativo para testes HTTP/REST
- Scripting em JavaScript
- M√©tricas detalhadas out-of-the-box
- Facilidade de automa√ß√£o
- Gera√ß√£o de relat√≥rios estruturados

#### 6.1.2 Scripts de Teste

**Teste Normal:** `scripts/load-test.js`
- Virtual Users (VUs): 50
- Dura√ß√£o: 5 minutos
- Ramp-up: 30 segundos
- Opera√ß√µes: 70% GET, 30% POST

**Teste de Stress:** `scripts/load-test-stress.js`
- Virtual Users (VUs): 100
- Dura√ß√£o: 5 minutos
- Ramp-up: 30 segundos
- Opera√ß√µes: 70% GET, 30% POST

### 6.2 Cen√°rio 1 - Baseline (Sem Autoscaling)

#### 6.2.1 Configura√ß√£o

**Deployment:**
- Gateway: 1 r√©plica fixa
- Service-A: 1 r√©plica fixa
- Service-B: 1 r√©plica fixa
- HPA: Desabilitado

**Objetivo:**
Estabelecer uma linha de base de desempenho da aplica√ß√£o sem nenhuma otimiza√ß√£o de escalabilidade.

#### 6.2.2 Execu√ß√£o

Script: `scripts/cenario1_baseline.sh`

```bash
#!/bin/bash
# Cen√°rio 1 - Baseline sem autoscaling
kubectl apply -f k8s/namespace.yaml
kubectl apply -f k8s/gateway-deployment.yaml
kubectl apply -f k8s/service-a-deployment.yaml
kubectl apply -f k8s/service-b-deployment.yaml
kubectl apply -f k8s/gateway-service.yaml
kubectl apply -f k8s/service-a-service.yaml
kubectl apply -f k8s/service-b-service.yaml

# Aguardar pods ficarem prontos
kubectl wait --for=condition=ready pod -l app=gateway -n grpc-app --timeout=120s
kubectl wait --for=condition=ready pod -l app=service-a -n grpc-app --timeout=120s
kubectl wait --for=condition=ready pod -l app=service-b -n grpc-app --timeout=120s

# Expor gateway
./scripts/expose_gateway.sh

# Executar teste
k6 run scripts/load-test.js
```

#### 6.2.3 Resultados

Arquivo: `scripts/results/load-tests/load-test-20251206_210721.txt`

**M√©tricas Principais:**
- **Requests Total:** 14,932
- **Requests/segundo:** ~49.77 req/s
- **Lat√™ncia M√©dia:** 100.47ms
- **Lat√™ncia p95:** 206.87ms
- **Lat√™ncia p99:** 272.59ms
- **Taxa de Sucesso:** 100%
- **Throughput:** 42.65 KB/s

**M√©tricas por Endpoint:**

| Endpoint | Requests | Lat√™ncia M√©dia | p95 | p99 | Taxa Erro |
|----------|----------|----------------|-----|-----|-----------|
| GET /users | 10,441 | 99.93ms | 205.94ms | 270.67ms | 0% |
| POST /users | 4,491 | 101.54ms | 208.94ms | 277.43ms | 0% |

**Observa√ß√µes:**
- Sistema est√°vel durante todo o teste
- Lat√™ncia consistente
- Nenhum erro observado
- CPU do Gateway: ~40-50%
- CPU dos Services: ~20-30%
- Mem√≥ria est√°vel

#### 6.2.4 Conclus√µes

‚úÖ **Pontos Positivos:**
- Sistema funciona adequadamente em carga moderada
- N√£o apresenta erros
- Lat√™ncia aceit√°vel para aplica√ß√µes n√£o-cr√≠ticas

‚ùå **Limita√ß√µes:**
- N√£o escala para cargas maiores
- Recursos subutilizados em momentos de baixa demanda
- Risco de degrada√ß√£o em picos de tr√°fego

### 6.3 Cen√°rio 2 - Pr√©-Escalado (Sem HPA)

#### 6.3.1 Configura√ß√£o

**Deployment:**
- Gateway: 3 r√©plicas fixas
- Service-A: 3 r√©plicas fixas
- Service-B: 3 r√©plicas fixas
- HPA: Desabilitado

**Objetivo:**
Avaliar o impacto de escalar manualmente a aplica√ß√£o para m√∫ltiplas r√©plicas, sem usar autoscaling din√¢mico.

#### 6.3.2 Execu√ß√£o

Script: `scripts/cenario2_pre_escalado.sh`

```bash
#!/bin/bash
# Cen√°rio 2 - Aplica√ß√£o pr√©-escalada (3 r√©plicas)
kubectl scale deployment gateway -n grpc-app --replicas=3
kubectl scale deployment service-a -n grpc-app --replicas=3
kubectl scale deployment service-b -n grpc-app --replicas=3

# Aguardar scale up
kubectl wait --for=condition=ready pod -l app=gateway -n grpc-app --timeout=120s
kubectl wait --for=condition=ready pod -l app=service-a -n grpc-app --timeout=120s
kubectl wait --for=condition=ready pod -l app=service-b -n grpc-app --timeout=120s

# Executar teste
k6 run scripts/load-test.js
```

#### 6.3.3 Resultados

Arquivo: `scripts/results/load-tests/cenario2-pre-escalado-20251206_213349.txt`

**M√©tricas Principais:**
- **Requests Total:** 14,951
- **Requests/segundo:** ~49.83 req/s
- **Lat√™ncia M√©dia:** 100.12ms
- **Lat√™ncia p95:** 206.43ms
- **Lat√™ncia p99:** 271.88ms
- **Taxa de Sucesso:** 100%
- **Throughput:** 42.71 KB/s

**M√©tricas por Endpoint:**

| Endpoint | Requests | Lat√™ncia M√©dia | p95 | p99 | Taxa Erro |
|----------|----------|----------------|-----|-----|-----------|
| GET /users | 10,460 | 99.67ms | 205.59ms | 269.97ms | 0% |
| POST /users | 4,491 | 101.05ms | 208.34ms | 276.12ms | 0% |

**Uso de Recursos:**
- CPU Gateway: ~15-25% por pod
- CPU Service-A: ~10-15% por pod
- CPU Service-B: ~8-12% por pod
- Mem√≥ria: Est√°vel em todos os pods
- Load balancing: Bem distribu√≠do entre r√©plicas

**Observa√ß√µes:**
- Desempenho praticamente id√™ntico ao Cen√°rio 1
- Recursos significativamente subutilizados
- Load balancer do K8s distribuiu bem as requisi√ß√µes
- Custo computacional 3x maior sem ganho de performance

#### 6.3.4 Conclus√µes

‚úÖ **Pontos Positivos:**
- Alta disponibilidade (toler√¢ncia a falhas)
- Redund√¢ncia em caso de crash de pod
- Sistema preparado para spikes instant√¢neos

‚ùå **Limita√ß√µes:**
- **Desperd√≠cio de recursos** - CPUs ociosas
- N√£o h√° melhoria de lat√™ncia ou throughput
- Custo operacional desnecessariamente alto
- Estrat√©gia inadequada para carga constante

**Insight Importante:**
Para a carga testada (50 VUs), uma √∫nica r√©plica √© suficiente. Escalar manualmente para 3 r√©plicas n√£o trouxe benef√≠cios mensur√°veis, apenas aumentou o consumo de recursos.

### 6.4 Cen√°rio 3 - HPA Agressivo

#### 6.4.1 Configura√ß√£o

**Deployment:**
- Gateway: 1-5 r√©plicas (HPA agressivo)
- Service-A: 1-5 r√©plicas (HPA agressivo)
- Service-B: 1-5 r√©plicas (HPA agressivo)
- HPA: Habilitado com configura√ß√µes agressivas

**HPA Settings:**
```yaml
minReplicas: 1
maxReplicas: 5
targetCPUUtilization: 50%
scaleUpStabilizationWindow: 0s
scaleDownStabilizationWindow: 60s
```

**Objetivo:**
Testar se um HPA configurado agressivamente (threshold baixo, escala r√°pida) consegue melhorar o desempenho comparado ao baseline.

#### 6.4.2 Execu√ß√£o

Script: `scripts/cenario3_hpa_agressivo.sh`

```bash
#!/bin/bash
# Cen√°rio 3 - HPA Agressivo
kubectl apply -f k8s/hpa-agressivo.yaml

# Resetar r√©plicas para baseline
kubectl scale deployment gateway -n grpc-app --replicas=1
kubectl scale deployment service-a -n grpc-app --replicas=1
kubectl scale deployment service-b -n grpc-app --replicas=1

# Aguardar estabiliza√ß√£o
sleep 60

# Executar teste
k6 run scripts/load-test.js
```

#### 6.4.3 Resultados

Arquivo: `scripts/results/load-tests/cenario3-hpa-agressivo-20251206_215628.txt`

**M√©tricas Principais:**
- **Requests Total:** 14,951
- **Requests/segundo:** ~49.83 req/s
- **Lat√™ncia M√©dia:** 100.39ms
- **Lat√™ncia p95:** 207.19ms
- **Lat√™ncia p99:** 273.23ms
- **Taxa de Sucesso:** 100%
- **Throughput:** 42.71 KB/s

**M√©tricas por Endpoint:**

| Endpoint | Requests | Lat√™ncia M√©dia | p95 | p99 | Taxa Erro |
|----------|----------|----------------|-----|-----|-----------|
| GET /users | 10,460 | 99.97ms | 206.27ms | 271.37ms | 0% |
| POST /users | 4,491 | 101.21ms | 209.17ms | 277.98ms | 0% |

**Comportamento do HPA:**
- In√≠cio: 1 r√©plica de cada servi√ßo
- Aos 2 minutos: HPA escalou Gateway para 2 r√©plicas (CPU ~60%)
- Aos 3 minutos: HPA escalou Service-A para 2 r√©plicas
- Aos 4 minutos: Gateway chegou a 3 r√©plicas
- Final: Manteve 3 r√©plicas de Gateway, 2 de Service-A, 1 de Service-B

**Observa√ß√µes:**
- HPA reagiu rapidamente ao aumento de CPU
- Escala aconteceu de forma gradual durante o teste
- N√£o houve impacto negativo durante a escalada
- Desempenho final equivalente aos cen√°rios anteriores

#### 6.4.4 Conclus√µes

‚úÖ **Pontos Positivos:**
- HPA funcionou como esperado
- Escalou preventivamente quando necess√°rio
- Sistema se adaptou √† demanda

‚ùå **Limita√ß√µes:**
- N√£o melhorou lat√™ncia ou throughput
- Para esta carga espec√≠fica, autoscaling n√£o foi necess√°rio
- Overhead de gerenciamento do HPA

**Insight Importante:**
O HPA agressivo n√£o trouxe melhorias de desempenho porque **a carga de 50 VUs n√£o foi suficiente para saturar um √∫nico pod**. O autoscaling s√≥ faz sentido quando h√° real necessidade de recursos adicionais.

### 6.5 Cen√°rio 4 - Stress Test com HPA Agressivo

#### 6.5.1 Configura√ß√£o

**Deployment:**
- Gateway: 1-5 r√©plicas (HPA agressivo)
- Service-A: 1-5 r√©plicas (HPA agressivo)
- Service-B: 1-5 r√©plicas (HPA agressivo)
- HPA: Habilitado com configura√ß√µes agressivas

**Teste de Stress:**
- Virtual Users: **100** (2x o teste normal)
- Dura√ß√£o: 5 minutos
- Ramp-up: 30 segundos

**Objetivo:**
Levar a aplica√ß√£o ao limite e observar como o HPA agressivo reage a uma carga real de stress, validando a necessidade e efic√°cia do autoscaling.

#### 6.5.2 Execu√ß√£o

Script: `scripts/cenario4_stress_test.sh`

```bash
#!/bin/bash
# Cen√°rio 4 - Stress Test com 100 VUs
kubectl apply -f k8s/hpa-agressivo.yaml

# Resetar para baseline
kubectl scale deployment gateway -n grpc-app --replicas=1
kubectl scale deployment service-a -n grpc-app --replicas=1
kubectl scale deployment service-b -n grpc-app --replicas=1

# Aguardar estabiliza√ß√£o
sleep 60

# Executar stress test
k6 run scripts/load-test-stress.js
```

#### 6.5.3 Resultados

Arquivo: `scripts/results/load-tests/cenario4-stress-test-20251206_220923.txt`

**M√©tricas Principais:**
- **Requests Total:** 26,799
- **Requests/segundo:** ~89.33 req/s
- **Lat√™ncia M√©dia:** 166.79ms (+66% vs baseline)
- **Lat√™ncia p95:** 417.85ms (+102% vs baseline)
- **Lat√™ncia p99:** 551.70ms (+102% vs baseline)
- **Taxa de Sucesso:** 100%
- **Throughput:** 76.51 KB/s

**M√©tricas por Endpoint:**

| Endpoint | Requests | Lat√™ncia M√©dia | p95 | p99 | Taxa Erro |
|----------|----------|----------------|-----|-----|-----------|
| GET /users | 18,756 | 167.14ms | 418.93ms | 553.21ms | 0% |
| POST /users | 8,043 | 165.95ms | 415.25ms | 548.42ms | 0% |

**Comportamento do HPA Durante o Teste:**

| Tempo | Gateway | Service-A | Service-B | CPU Gateway | Observa√ß√£o |
|-------|---------|-----------|-----------|-------------|------------|
| 0:00 | 1 | 1 | 1 | ~30% | In√≠cio do teste |
| 0:30 | 1 | 1 | 1 | ~75% | Ramp-up completo |
| 1:00 | 2 | 1 | 1 | ~65% | HPA escala Gateway |
| 1:30 | 3 | 2 | 1 | ~55% | HPA escala ambos |
| 2:00 | 4 | 2 | 1 | ~50% | Gateway atinge 4 r√©plicas |
| 3:00 | 5 | 3 | 2 | ~45% | Escalamento m√°ximo |
| 4:00 | 5 | 3 | 2 | ~42% | Estabilizado |
| 5:00 | 5 | 3 | 2 | ~40% | Fim do teste |

**Gr√°fico de Lat√™ncia ao Longo do Tempo:**
- Minuto 0-1: Lat√™ncia ~150-200ms (1 r√©plica, sobrecarga)
- Minuto 1-2: Lat√™ncia ~140-170ms (2-3 r√©plicas, melhorando)
- Minuto 2-5: Lat√™ncia ~120-150ms (4-5 r√©plicas, estabilizado)

**Uso de Recursos (Pico):**
- CPU Gateway: 80-90% (antes de escalar)
- CPU Service-A: 60-70% (antes de escalar)
- CPU Service-B: 40-50%
- Mem√≥ria: Est√°vel (~150-200MB por pod)
- Network I/O: ~5-8 MB/s

#### 6.5.4 An√°lise Comparativa

**Compara√ß√£o com Baseline (Cen√°rio 1):**

| M√©trica | Baseline (50 VUs) | Stress (100 VUs) | Varia√ß√£o |
|---------|-------------------|------------------|----------|
| Requests/s | 49.77 | 89.33 | +79.5% |
| Lat√™ncia M√©dia | 100.47ms | 166.79ms | +66.0% |
| Lat√™ncia p95 | 206.87ms | 417.85ms | +102.0% |
| Lat√™ncia p99 | 272.59ms | 551.70ms | +102.4% |
| R√©plicas Finais | 1-1-1 | 5-3-2 | - |
| Taxa de Erro | 0% | 0% | 0% |

**Observa√ß√µes:**
- Throughput quase dobrou (79.5% de aumento)
- Lat√™ncia aumentou significativamente, mas permaneceu aceit√°vel
- Sistema manteve 100% de disponibilidade
- HPA conseguiu estabilizar o sistema em carga extrema

#### 6.5.5 Conclus√µes

‚úÖ **Pontos Positivos:**
- **HPA foi efetivo:** Sistema escalou automaticamente e se adaptou √† demanda
- **Alta resili√™ncia:** 100% de disponibilidade mesmo sob stress
- **Escalamento adequado:** Atingiu configura√ß√£o ideal (5-3-2) para suportar a carga
- **Sem erros:** Taxa de erro zero mesmo em condi√ß√µes extremas

‚ö†Ô∏è **Pontos de Aten√ß√£o:**
- **Lat√™ncia degradada:** Aumento de 66-102% na lat√™ncia sob stress
- **Trade-off necess√°rio:** Mais throughput = maior lat√™ncia
- **Tempo de rea√ß√£o:** HPA levou ~2 minutos para estabilizar completamente

üí° **Insights:**
1. **Autoscaling √© necess√°rio:** Diferente dos cen√°rios anteriores, aqui o HPA demonstrou valor real
2. **Configura√ß√£o agressiva foi adequada:** Scale-up r√°pido evitou degrada√ß√£o maior
3. **Sistema bem dimensionado:** Com recursos suficientes, suportou 2x a carga prevista
4. **Threshold de 50% foi adequado:** Permitiu margem de seguran√ßa

#### 6.5.6 Recomenda√ß√µes Baseadas no Stress Test

**Para Produ√ß√£o:**
1. Manter HPA agressivo em ambientes com carga vari√°vel
2. Considerar min replicas = 2 para reduzir tempo de resposta inicial
3. Monitorar lat√™ncia p95 como m√©trica cr√≠tica de SLA
4. Configurar alertas para lat√™ncia > 300ms
5. Considerar cache ou otimiza√ß√µes para reduzir lat√™ncia sob carga

**Limites Identificados:**
- **Carga suport√°vel com 1 r√©plica:** ~50 req/s
- **Carga suport√°vel com HPA (max 5):** ~90 req/s
- **SLA de lat√™ncia recomendado:** < 200ms p95 (requer ~2-3 r√©plicas m√≠nimas)

### 6.6 An√°lise Comparativa Consolidada

#### 6.6.1 Tabela Resumo dos Cen√°rios

| M√©trica | Cen√°rio 1 (Baseline) | Cen√°rio 2 (Pr√©-Escalado) | Cen√°rio 3 (HPA Agressivo) | Cen√°rio 4 (Stress + HPA) |
|---------|----------------------|--------------------------|---------------------------|--------------------------|
| **VUs** | 50 | 50 | 50 | 100 |
| **R√©plicas Inicial** | 1-1-1 | 3-3-3 | 1-1-1 | 1-1-1 |
| **R√©plicas Final** | 1-1-1 | 3-3-3 | 3-2-1 | 5-3-2 |
| **Requests Total** | 14,932 | 14,951 | 14,951 | 26,799 |
| **Requests/s** | 49.77 | 49.83 | 49.83 | 89.33 |
| **Lat√™ncia M√©dia** | 100.47ms | 100.12ms | 100.39ms | 166.79ms |
| **Lat√™ncia p95** | 206.87ms | 206.43ms | 207.19ms | 417.85ms |
| **Lat√™ncia p99** | 272.59ms | 271.88ms | 273.23ms | 551.70ms |
| **Taxa de Erro** | 0% | 0% | 0% | 0% |
| **CPU Utiliza√ß√£o** | M√©dia | Baixa | M√©dia‚ÜíAlta | Alta‚ÜíM√©dia |
| **Custo Recursos** | Baixo | Alto | Baixo‚ÜíM√©dio | M√©dio‚ÜíAlto |

#### 6.6.2 Gr√°ficos Comparativos

**Gr√°fico 1: Lat√™ncia p95 por Cen√°rio**
```
Lat√™ncia p95 (ms)
500 |                                            ‚óè
400 |                                            |  (417.85ms)
300 |                                            |
200 |    ‚óè‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚óè‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚óè                     |
100 |  (206.87)                                  |
  0 +‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ+
      C1       C2       C3                    C4
```

**Gr√°fico 2: Throughput por Cen√°rio**
```
Requests/segundo
100 |                                            ‚óè
 80 |                                            |  (89.33)
 60 |                                            |
 40 |    ‚óè‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚óè‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚óè                     |
 20 |  (~50)                                     |
  0 +‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ+
      C1       C2       C3                    C4
```

**Gr√°fico 3: N√∫mero de R√©plicas ao Longo do Tempo (Cen√°rio 4)**
```
R√©plicas
5 |              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
4 |          ‚îå‚îÄ‚îÄ‚îÄ‚îò
3 |      ‚îå‚îÄ‚îÄ‚îÄ‚îò
2 |  ‚îå‚îÄ‚îÄ‚îÄ‚îò
1 |‚îÄ‚îÄ‚îò
0 +‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  0    1    2    3    4    5 (minutos)
     Gateway (linha cheia)
```

#### 6.6.3 Principais Descobertas

**1. Para Cargas Moderadas (50 VUs):**
- Uma √∫nica r√©plica √© suficiente
- Pr√©-escalar desperdi√ßa recursos sem ganho de performance
- HPA n√£o traz benef√≠cios mensur√°veis

**2. Para Cargas Altas (100 VUs):**
- Autoscaling √© essencial
- HPA agressivo permite adapta√ß√£o r√°pida
- Trade-off entre throughput e lat√™ncia

**3. Sobre Autoscaling:**
- Configura√ß√£o agressiva (threshold 50%) √© recomendada
- Scale-up deve ser r√°pido (sem janela de estabiliza√ß√£o)
- Scale-down deve ser cauteloso (janela de 60s)

**4. Sobre Monitoramento:**
- CPU √© uma boa m√©trica para HPA
- Lat√™ncia p95 √© crucial para SLA
- Taxa de erro zero em todos os cen√°rios indica robustez

---

## 7. Conclus√µes e Considera√ß√µes Finais

### 7.1 Conclus√µes Gerais

Este projeto permitiu uma compreens√£o profunda sobre monitoramento, observabilidade e autoscaling em ambientes Kubernetes com aplica√ß√µes baseadas em microservi√ßos. Atrav√©s dos quatro cen√°rios de teste executados, pudemos validar empiricamente conceitos te√≥ricos e tomar decis√µes informadas sobre arquitetura e configura√ß√£o.

#### 7.1.1 Sobre a Aplica√ß√£o

A arquitetura de microservi√ßos com comunica√ß√£o gRPC demonstrou:
- **Alta confiabilidade:** 0% de taxa de erro em todos os cen√°rios
- **Performance adequada:** Lat√™ncias aceit√°veis para aplica√ß√µes web
- **Escalabilidade horizontal:** Sistema se beneficia de r√©plicas adicionais sob carga real
- **Simplicidade operacional:** Deployments e configura√ß√µes relativamente simples

#### 7.1.2 Sobre o Kubernetes

O cluster Kubernetes multi-n√≥ permitiu:
- **Distribui√ß√£o efetiva:** Load balancing autom√°tico entre r√©plicas
- **Resili√™ncia:** Toler√¢ncia a falhas atrav√©s de m√∫ltiplos n√≥s
- **Flexibilidade:** F√°cil ajuste de r√©plicas e recursos
- **Observabilidade nativa:** Integra√ß√£o natural com Prometheus/Grafana

#### 7.1.3 Sobre Autoscaling

As conclus√µes mais importantes sobre HPA:

‚úÖ **Quando usar autoscaling:**
- Aplica√ß√µes com carga vari√°vel e imprevis√≠vel
- Ambientes onde custo operacional √© uma preocupa√ß√£o
- Sistemas que precisam responder a spikes de tr√°fego
- Cargas que efetivamente saturam pods individuais

‚ùå **Quando N√ÉO usar autoscaling:**
- Carga constante e previs√≠vel (melhor usar r√©plicas fixas)
- Carga baixa que n√£o justifica overhead do HPA
- Aplica√ß√µes stateful com complexidade de escala
- Quando lat√™ncia extra de scale-up √© inaceit√°vel

#### 7.1.4 Sobre Monitoramento e Observabilidade

Prometheus e Grafana provaram ser:
- **Essenciais:** Imposs√≠vel otimizar sem m√©tricas concretas
- **Completos:** Cobrem m√©tricas de sistema, aplica√ß√£o e K8S
- **Acess√≠veis:** Relativamente f√°ceis de configurar e usar
- **Poderosos:** Permitem an√°lises profundas e correla√ß√µes

### 7.2 Dificuldades Encontradas e Solu√ß√µes

#### 7.2.1 Networking e Port Forwarding
**Problema:** Conflitos de porta 8080 entre execu√ß√µes de testes.  
**Solu√ß√£o:** Implementa√ß√£o de script `expose_gateway.sh` que mata processos conflitantes automaticamente.

#### 7.2.2 Configura√ß√£o do Cluster Multi-n√≥
**Problema:** Complexidade inicial em configurar n√≥s worker corretamente.  
**Solu√ß√£o:** Desenvolvimento de script automatizado `setup_cluster.sh` com valida√ß√µes.

#### 7.2.3 M√©tricas do Prometheus
**Problema:** ServiceMonitors n√£o coletavam m√©tricas customizadas da aplica√ß√£o.  
**Solu√ß√£o:** Instrumenta√ß√£o adequada dos servi√ßos com endpoints `/metrics`.

#### 7.2.4 Tempo de Estabiliza√ß√£o do HPA
**Problema:** HPA demorava para reagir a mudan√ßas de carga.  
**Solu√ß√£o:** Configura√ß√£o agressiva com janela de estabiliza√ß√£o zero para scale-up.

#### 7.2.5 Endpoint `/stats/:id`
**Problema:** Endpoint n√£o implementado completamente no Service-B.  
**Solu√ß√£o:** Documentado como limita√ß√£o conhecida; n√£o impactou objetivos principais.

### 7.3 Aprendizados Principais

1. **M√©tricas s√£o fundamentais:** Decis√µes baseadas em dados s√£o infinitamente superiores a suposi√ß√µes
2. **Autoscaling n√£o √© m√°gica:** S√≥ funciona quando h√° real necessidade de recursos
3. **Testes de stress revelam verdades:** Cen√°rios normais n√£o exp√µem limita√ß√µes reais
4. **K8S √© poderoso mas complexo:** Requer estudo e experimenta√ß√£o para dominar
5. **Observabilidade > Monitoramento:** Ver o que est√° acontecendo √© mais valioso que apenas coletar dados

### 7.4 Recomenda√ß√µes para Trabalhos Futuros

1. **Testar com m√©tricas customizadas:** HPA baseado em lat√™ncia ou RPS ao inv√©s de CPU
2. **Implementar distributed tracing:** Usar Jaeger ou OpenTelemetry para rastreamento completo
3. **Explorar service mesh:** Istio ou Linkerd para observabilidade avan√ßada
4. **Adicionar persist√™ncia:** Banco de dados real para testar stateful workloads
5. **Testar em cloud p√∫blica:** AWS EKS, GCP GKE ou Azure AKS para validar em produ√ß√£o real
6. **Implementar CI/CD:** Pipeline automatizado para build, test e deploy
7. **Adicionar chaos engineering:** Testar resili√™ncia com falhas injetadas
8. **Explorar vertical pod autoscaling:** VPA al√©m do HPA

### 7.5 Coment√°rios Pessoais dos Integrantes

#### 7.5.1 [Nome do Aluno 1]

**Contribui√ß√µes principais:**
- [Descrever suas contribui√ß√µes]

**Aprendizados:**
- [Descrever o que aprendeu]

**Desafios enfrentados:**
- [Descrever desafios pessoais]

**Autoavalia√ß√£o:** [Nota de 0 a 10]

---

#### 7.5.2 [Nome do Aluno 2]

**Contribui√ß√µes principais:**
- [Descrever suas contribui√ß√µes]

**Aprendizados:**
- [Descrever o que aprendeu]

**Desafios enfrentados:**
- [Descrever desafios pessoais]

**Autoavalia√ß√£o:** [Nota de 0 a 10]

---

#### 7.5.3 [Nome do Aluno 3]

**Contribui√ß√µes principais:**
- [Descrever suas contribui√ß√µes]

**Aprendizados:**
- [Descrever o que aprendeu]

**Desafios enfrentados:**
- [Descrever desafios pessoais]

**Autoavalia√ß√£o:** [Nota de 0 a 10]

---

#### 7.5.4 [Nome do Aluno 4]

**Contribui√ß√µes principais:**
- [Descrever suas contribui√ß√µes]

**Aprendizados:**
- [Descrever o que aprendeu]

**Desafios enfrentados:**
- [Descrever desafios pessoais]

**Autoavalia√ß√£o:** [Nota de 0 a 10]

---

## 8. Refer√™ncias Bibliogr√°ficas

[1] Arundel, J. and Domingus, J. **Cloud Native DevOps with Kubernetes ‚Äì Building, Deploying and Scaling Modern Applications in the Cloud**. O'Reilly, 2019.

[2] Kubernetes Documentation. **Horizontal Pod Autoscaling**. Dispon√≠vel em: https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/. Acesso em: 6 dez. 2025.

[3] Prometheus Documentation. **Overview**. Dispon√≠vel em: https://prometheus.io/docs/introduction/overview/. Acesso em: 6 dez. 2025.

[4] gRPC Documentation. **What is gRPC?**. Dispon√≠vel em: https://grpc.io/docs/what-is-grpc/. Acesso em: 6 dez. 2025.

[5] k6 Documentation. **Load Testing**. Dispon√≠vel em: https://k6.io/docs/. Acesso em: 6 dez. 2025.

[6] Minikube Documentation. **Multi-Node Clusters**. Dispon√≠vel em: https://minikube.sigs.k8s.io/docs/tutorials/multi_node/. Acesso em: 6 dez. 2025.

[7] Grafana Documentation. **Getting Started**. Dispon√≠vel em: https://grafana.com/docs/grafana/latest/getting-started/. Acesso em: 6 dez. 2025.

[8] Burns, B., Beda, J., Hightower, K. **Kubernetes: Up and Running**. O'Reilly, 2019.

[9] Protocol Buffers Documentation. **Overview**. Dispon√≠vel em: https://developers.google.com/protocol-buffers. Acesso em: 6 dez. 2025.

[10] Docker Documentation. **Get Started**. Dispon√≠vel em: https://docs.docker.com/get-started/. Acesso em: 6 dez. 2025.

---

## Anexos

### Anexo A - Arquivos de Configura√ß√£o Completos

#### A.1 Namespace
```yaml
# k8s/namespace.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: grpc-app
```

#### A.2 Gateway Deployment
```yaml
# k8s/gateway-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: gateway
  namespace: grpc-app
spec:
  replicas: 1
  selector:
    matchLabels:
      app: gateway
  template:
    metadata:
      labels:
        app: gateway
    spec:
      containers:
      - name: gateway
        image: gateway:latest
        imagePullPolicy: Never
        ports:
        - containerPort: 8080
        env:
        - name: SERVICE_A_ADDR
          value: "service-a:50051"
        - name: SERVICE_B_ADDR
          value: "service-b:50052"
        resources:
          requests:
            cpu: 100m
            memory: 128Mi
          limits:
            cpu: 500m
            memory: 256Mi
```

#### A.3 HPA Agressivo
```yaml
# k8s/hpa-agressivo.yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: gateway-hpa
  namespace: grpc-app
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: gateway
  minReplicas: 1
  maxReplicas: 5
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 50
  behavior:
    scaleUp:
      stabilizationWindowSeconds: 0
      policies:
      - type: Percent
        value: 100
        periodSeconds: 15
      - type: Pods
        value: 2
        periodSeconds: 15
    scaleDown:
      stabilizationWindowSeconds: 60
      policies:
      - type: Percent
        value: 50
        periodSeconds: 15
---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: service-a-hpa
  namespace: grpc-app
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: service-a
  minReplicas: 1
  maxReplicas: 5
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 50
  behavior:
    scaleUp:
      stabilizationWindowSeconds: 0
      policies:
      - type: Percent
        value: 100
        periodSeconds: 15
    scaleDown:
      stabilizationWindowSeconds: 60
---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: service-b-hpa
  namespace: grpc-app
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: service-b
  minReplicas: 1
  maxReplicas: 5
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 50
  behavior:
    scaleUp:
      stabilizationWindowSeconds: 0
      policies:
      - type: Percent
        value: 100
        periodSeconds: 15
    scaleDown:
      stabilizationWindowSeconds: 60
```

### Anexo B - Scripts de Automa√ß√£o

#### B.1 Setup do Cluster
```bash
# scripts/setup_cluster.sh
[Conte√∫do do script de setup]
```

#### B.2 Script de Load Test
```javascript
// scripts/load-test.js
[Conte√∫do do script k6]
```

### Anexo C - Instru√ß√µes de Replica√ß√£o

#### C.1 Pr√©-requisitos
- Docker Desktop instalado
- Minikube instalado
- kubectl instalado
- k6 instalado
- Helm instalado (para Prometheus)

#### C.2 Passo a Passo

**1. Clonar o reposit√≥rio:**
```bash
git clone [URL_DO_REPOSITORIO]
cd PSPD_Trabalho1
```

**2. Configurar o cluster:**
```bash
./scripts/setup_cluster.sh
```

**3. Instalar Prometheus:**
```bash
./scripts/setup_prometheus.sh
```

**4. Buildar e carregar imagens:**
```bash
./scripts/build_and_load_images.sh
```

**5. Fazer deploy da aplica√ß√£o:**
```bash
./scripts/deploy.sh
```

**6. Expor o gateway:**
```bash
./scripts/expose_gateway.sh
```

**7. Executar cen√°rios de teste:**
```bash
./scripts/cenario1_baseline.sh
./scripts/cenario2_pre_escalado.sh
./scripts/cenario3_hpa_agressivo.sh
./scripts/cenario4_stress_test.sh
```

### Anexo D - Links √öteis

- **Reposit√≥rio GitHub:** [URL]
- **Documenta√ß√£o do Projeto:** `docs/`
- **Resultados dos Testes:** `scripts/results/load-tests/`
- **Dashboards Grafana:** [Exportar e incluir JSON]

---

**Fim do Relat√≥rio**
